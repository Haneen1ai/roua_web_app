<!DOCTYPE html>
<html lang="ar">
<head>
<meta charset="UTF-8">
<title>واجهة رؤى</title>
<style>
  body{
    margin:0;background:#000;display:flex;justify-content:center;align-items:center;
    height:100vh;flex-direction:column;gap:16px;overflow:hidden
  }
  .bg{
    position:fixed;inset:0;width:100vw;height:100vh;object-fit:cover;user-select:none;
    -webkit-user-drag:none;pointer-events:none;background:#000
  }
  .controls{position:relative;z-index:2;display:flex;gap:12px}
  button{padding:10px 18px;border:0;border-radius:8px;cursor:pointer}
  #status{position:relative;z-index:2;color:#9eea9e;font-family:system-ui,Arial,sans-serif}
</style>
</head>
<body>
  <!-- الصورة الافتراضية -->
  <img src="{{ url_for('static', filename='roua.jpg') }}" id="bgImg" class="bg" alt="Roa Background">

  <!-- الفيديو أثناء كلام البوت -->
  <video id="rouaVideo"
         class="bg"
         src="{{ url_for('static', filename='roua.MP4') }}"
         autoplay
         muted
         playsinline
         loop
         style="display:none"></video>

  <div class="controls">
    <button id="start">بدء المحادثة</button>
    <button id="stop" disabled>إيقاف</button>
  </div>
  <div id="status"></div>

  <!-- صوت البوت -->
  <audio id="agent-audio" autoplay playsinline></audio>

  <script type="module">
    import { Conversation } from "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.5.0/+esm";

    const startBtn   = document.getElementById('start');
    const stopBtn    = document.getElementById('stop');
    const statusEl   = document.getElementById('status');
    const bgImg      = document.getElementById('bgImg');
    const vid        = document.getElementById('rouaVideo');
    const agentAudio = document.getElementById('agent-audio');

    let convo = null;

    function setStatus(t){ statusEl.textContent = t; }

    function showVideo(){
      bgImg.style.display = 'none';
      vid.style.display = 'block';
      vid.play().catch(()=>{});
    }
    function showImage(){
      vid.pause();
      vid.currentTime = 0;
      vid.style.display = 'none';
      bgImg.style.display = 'block';
    }

    function wireAudioEvents(){
      agentAudio.addEventListener('playing', showVideo);
      ['pause','ended','waiting','stalled','suspend','emptied'].forEach(ev=>{
        agentAudio.addEventListener(ev, showImage);
      });
    }

    async function start() {
      try {
        setStatus('نجهّز المايك…');
        const mic = await navigator.mediaDevices.getUserMedia({ audio: true });

        setStatus('نجيب توكن الجلسة…');
        const tokenRes = await fetch('/conversation-token');
        if (!tokenRes.ok) throw new Error('فشل جلب التوكن');
        const conversationToken = await tokenRes.text();

        setStatus('نبدأ الجلسة مع رؤى…');
        convo = await Conversation.startSession({
          conversationToken,
          connectionType: "webrtc",
          onConnect: () => setStatus('متصلة — تكلمي معها الآن ✨'),
          onDisconnect: () => { setStatus('انتهت الجلسة'); showImage(); },
          onError: (e) => setStatus(`خطأ: ${e?.message || e}`),
        });

        const remoteStream =
          (convo.getRemoteMediaStream && convo.getRemoteMediaStream()) ||
          (convo.getRemoteStream && convo.getRemoteStream()) || null;

        if (remoteStream) {
          agentAudio.srcObject = remoteStream;
          await agentAudio.play().catch(()=>{});
        }

        wireAudioEvents();
        showImage();

        startBtn.disabled = true;
        stopBtn.disabled  = false;
      } catch (err) {
        setStatus(`خطأ: ${err?.message || err}`);
      }
    }

    async function stop() {
      try {
        if (convo) {
          await convo.endSession();
          convo = null;
        }
      } finally {
        startBtn.disabled = false;
        stopBtn.disabled  = true;
        showImage();
        setStatus('أوقفت الجلسة.');
      }
    }

    startBtn.addEventListener('click', start);
    stopBtn.addEventListener('click', stop);
  </script>
</body>
</html>