<!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <title>واجهة رؤى</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body {
      margin: 0;
      background: #000;
      height: 100vh;
      width: 100vw;
      overflow: hidden;
      display: flex;
      align-items: center;
      justify-content: center;
      flex-direction: column;
    }
    img.bg {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      user-select: none;
      -webkit-user-drag: none;
      pointer-events: none;
    }
    button {
      position: relative;
      z-index: 2;
      padding: 16px 24px;
      font-size: 18px;
      cursor: pointer;
      background: #fff;
      border: none;
      border-radius: 8px;
    }
  </style>
</head>
<body>
  <img src="{{ url_for('static', filename='roua.jpg') }}" class="bg" alt="Roa Background" />
  <button id="startBtn">ابدأ المحادثة الصوتية</button>

  <audio id="botAudio" autoplay playsinline></audio>

  <script>
    const startBtn = document.getElementById('startBtn');
    const botAudio = document.getElementById('botAudio');

    async function unlockAudio() {
      try {
        const ctx = new (window.AudioContext || window.webkitAudioContext)();
        if (ctx.state === 'suspended') await ctx.resume();
      } catch (_) {}
    }

    startBtn.addEventListener('click', async () => {
      startBtn.disabled = true;
      await unlockAudio();

      try {
        const token = await fetch('/conversation-token').then(r => r.text());
        if (!token  token.startsWith('Missing')  token.startsWith('Failed')) {
          alert('فشل جلب التوكن من السيرفر'); startBtn.disabled = false; return;
        }

        const pc = new RTCPeerConnection({
          iceServers: [{ urls: ['stun:stun.l.google.com:19302'] }]
        });

        const remoteStream = new MediaStream();
        pc.addEventListener('track', (e) => {
          remoteStream.addTrack(e.track);
          botAudio.srcObject = remoteStream;
          botAudio.muted = false;
          botAudio.volume = 1.0;
          botAudio.play().catch(()=>{});
        });

        const mic = await navigator.mediaDevices.getUserMedia({ audio: true });
        mic.getTracks().forEach(t => pc.addTrack(t, mic));

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);

        const resp = await fetch(
          'https://api.elevenlabs.io/v1/convai/conversation/websocket/webrtc',
          {
            method: 'POST',
            headers: { 'Authorization': Bearer ${token}, 'Content-Type': 'application/sdp' },
            body: offer.sdp
          }
        );

        if (!resp.ok) {
          console.error(await resp.text());
          alert('فشل تهيئة اتصال WebRTC مع ElevenLabs');
          startBtn.disabled = false; return;
        }

        const answerSdp = await resp.text();
        await pc.setRemoteDescription({ type: 'answer', sdp: answerSdp });

      } catch (err) {
        console.error(err);
        alert('صار خطأ في بدء الاتصال الصوتي');
        startBtn.disabled = false;
      }
    });
  </script>
</body>
</html>